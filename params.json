{
  "name": "Essence",
  "tagline": "Essence is a library for Natural Language Processing and Text Summarization in Elixir.",
  "body": "[![Build Status](https://semaphoreci.com/api/v1/nicbet/essence/branches/master/shields_badge.svg)](https://semaphoreci.com/nicbet/essence)\r\n![Project Stage](https://img.shields.io/badge/stage-pre--alpha-red.svg)\r\n\r\n# Essence\r\n\r\nEssence is a Natural Language Processing (NLP) and Text Summarization library for Elixir. The work is currently in very early stages.\r\n\r\n## Installation\r\n\r\nIf [available in Hex](https://hex.pm/docs/publish), the package can be installed as:\r\n\r\n  1. Add `essence` to your list of dependencies in `mix.exs`:\r\n\r\n    ```elixir\r\n    def deps do\r\n      [{:essence, \"~> 0.1.0\"}]\r\n    end\r\n    ```\r\n\r\n## Examples\r\n\r\nIn the following examples we will use `test/genesis.txt`, which is a copy of\r\nthe book of genesis from the King James Bible\r\n(http://www.gutenberg.org/ebooks/8001.txt.utf-8).\r\n\r\nWe provide a convenience method for reading the plain text of the book of\r\ngenesis into `Essence` via the method `Essence.genesis/1`\r\n\r\nLet's first create a document from the text:\r\n\r\n  ```elixir\r\n  iex> document = Essence.Document.from_text Essence.genesis\r\n  ```\r\n\r\nWe can see that the text contains 1,533 paragraphs, 1,663 sentences and 44,741 tokens.\r\n  ```elixir\r\n  iex> document |> Essence.Document.enumerate_tokens |> Enum.count\r\n  iex> document |> Essence.Document.paragraphs |> Enum.count\r\n  iex> document |> Essence.Document.sentences |> Enum.count\r\n  ```\r\n\r\nWhat might the first sentence of genesis be?\r\n  ```elixir\r\n  iex> Essence.Document.sentence document, 0\r\n  ```\r\n\r\nNow let's compute the frequency distribution for tokens in the book of genesis:\r\n  ```elixir\r\n  iex> fd = Essence.Vocabulary.freq_dist document\r\n  ```\r\n\r\nWhat is the vocabulary of this text?\r\n  ```elixir\r\n  iex> vocabulary = Essence.Vocabulary.vocabulary document\r\n  ```\r\n  or alternatively we can use the frequency distribution for the equivalent expression:\r\n  ```elixir\r\n  iex> vocabulary = Map.keys fd\r\n  ```\r\n\r\nWhat might the top 10 most frequent tokens be?\r\n  ```elixir\r\n  iex> vocabulary |> Enum.sort_by( fn(x) -> Map.get(fd, x) end, &>=/2 ) |> Enum.slice(1, 10)\r\n  [\"and\", \"the\", \"of\", \".\", \"And\", \":\", \"his\", \"he\", \"to\", \";\"]\r\n  ```\r\n\r\nNext, we can compute the lexical richness of the text:\r\n  ```elixir\r\n  iex> Essence.Vocabulary.lexical_richness document\r\n  16.74438622754491\r\n  ```\r\n\r\n## ToDo\r\n\r\n- [x] Tokenization (Basic, done)\r\n- [x] Sentence Detection and Chunking (Basic, done)\r\n- [x] Vocabulary (Basic, done)\r\n- [x] Documents (Draft, done)\r\n- [ ] *Readability* (ARI done, SMOG in progress, FC, GF, DC, CL todo)\r\n- [ ] Corpora\r\n- [ ] Bi-Grams\r\n- [ ] Tri-Grams\r\n- [ ] n-Grams\r\n- [ ] Frequency Measures\r\n- [ ] Time-Series Documents\r\n- [ ] Dispersion\r\n- [ ] Similarity Measures\r\n- [ ] Part of Speech Tagging\r\n- [ ] Sentiment Analysis\r\n- [ ] Classification\r\n- [ ] Summarization\r\n- [ ] Document Hierarchies\r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}